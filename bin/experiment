#!/usr/bin/env python
# -*- coding: utf-8 -*-
from __future__ import absolute_import
from __future__ import print_function
from __future__ import division

import tensorflow as tf

from textsum.dataset import run_article_experiment, Article
from textsum.models import create_article_model


tf.flags.DEFINE_string('model_dir', 'model', 'model directory')
tf.flags.DEFINE_string('dataset_dir', 'records/medium', 'data directory')
tf.flags.DEFINE_string('input_feature', 'text', 'input feature')
tf.flags.DEFINE_string('target_feature', 'tags', 'target feature')
tf.flags.DEFINE_string('schedule', 'train', 'experiment schedule')

FLAGS = tf.flags.FLAGS


def main(_):
  hparams = tf.contrib.training.HParams(
    optimizer='Adam',
    batch_size=32,
    use_bidirectional=True,
    shuffle_buffer_size=100,
    epochs=10000,
    learning_rate=1e-4,
    max_gradient_norm=5.,
    input_embedding_size=512,
    target_embedding_size=512,
    input_encoder_cell_type='lstm',
    target_decoder_cell_type='lstm',
    attention_mechanism='luong',
    input_n_encoder_units=128,
    input_n_encoder_layers=8,
    target_n_decoder_units=128,
    target_n_decoder_layers=8)

  mode = None
  if FLAGS.schedule == 'train':
    mode = tf.contrib.learn.ModeKeys.TRAIN
  elif FLAGS.schedule == 'evaluate':
    mode = tf.contrib.learn.ModeKeys.INFER

  run_article_experiment(create_article_model, hparams,
                         mode=mode,
                         input_feature=FLAGS.input_feature,
                         target_feature=FLAGS.target_feature,
                         validation_size=10,
                         max_input_sequence_length=Article.max_lookup[FLAGS.input_feature],
                         max_target_sequence_length=Article.max_lookup[FLAGS.target_feature],
                         dataset_dir=FLAGS.dataset_dir,
                         model_dir=FLAGS.model_dir)


if __name__ == '__main__':
  tf.app.run()
